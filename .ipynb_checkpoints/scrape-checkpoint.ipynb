{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffff413",
   "metadata": {},
   "source": [
    "## Get Basic Yelp Restaurant Data\n",
    "Yelp API Guide: https://docs.developer.yelp.com/docs/fusion-intro. Uses the v3/businesses/search endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037cbc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T01:37:54.022915Z",
     "start_time": "2023-11-17T01:37:53.935543Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import string\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4efaae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:33:59.773074Z",
     "start_time": "2023-11-11T00:33:59.761205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate Manhattan specific restuarants by neighborhood for more granular results.\n",
    "neighborhoods = [\n",
    "    \"Alphabet City\",\n",
    "    \"Battery Park City\",\n",
    "    \"Bowery\",\n",
    "    \"Bryant Park\",\n",
    "    \"Carnegie Hill\",\n",
    "    \"Central Park\",\n",
    "    \"Chelsea\",\n",
    "    \"Chinatown\",\n",
    "    \"Civic Center\",\n",
    "    \"Clinton\",\n",
    "    \"East Harlem\",\n",
    "    \"East Village\",\n",
    "    \"Financial District\",\n",
    "    \"Flatiron\",\n",
    "    \"Fort George\",\n",
    "    \"Garment District\",\n",
    "    \"Gramercy\",\n",
    "    \"Greenwich Village\",\n",
    "    \"Hamilton Heights\",\n",
    "    \"Harlem\",\n",
    "    \"Hells Kitchen\",\n",
    "    \"Hudson Heights\",\n",
    "    \"Hudson Square\",\n",
    "    \"Hudson Yards\",\n",
    "    \"Inwood\",\n",
    "    \"Kips Bay\",\n",
    "    \"Lenox Hill\",\n",
    "    \"Lincoln Square\",\n",
    "    \"Little Italy\",\n",
    "    \"Lower East Side\",\n",
    "    \"Manhattan Valley\",\n",
    "    \"Manhattanville\",\n",
    "    \"Meatpacking\",\n",
    "    \"Midtown\",\n",
    "    \"Midtown East\",\n",
    "    \"Midtown South\",\n",
    "    \"Midtown West\",\n",
    "    \"Morningside Heights\",\n",
    "    \"Murray Hill\",\n",
    "    \"Noho\",\n",
    "    \"Nolita\",\n",
    "    \"NoMad\",\n",
    "    \"Roosevelt Island\",\n",
    "    \"Soho\",\n",
    "    \"Stuyvesant Town\",\n",
    "    \"Sutton Place\",\n",
    "    \"Times Square\",\n",
    "    \"Theater District\",\n",
    "    \"Tribeca\",\n",
    "    \"Tudor City\",\n",
    "    \"Turtle Bay\",\n",
    "    \"Two Bridges\",\n",
    "    \"Union Square\",\n",
    "    \"Upper East Side\",\n",
    "    \"Upper West Side\",\n",
    "    \"Washington Heights\",\n",
    "    \"Washington Square Park\",\n",
    "    \"West Harlem\",\n",
    "    \"West Village\",\n",
    "    \"Yorkville\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e34197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:01:04.749938Z",
     "start_time": "2023-11-11T00:01:04.744671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yelp allows inly 500 API calls per day, so we rotate btwn 3 different keys for maximum data collection.\n",
    "kKeyIndex = 0\n",
    "keys = [\n",
    "    \"ZF5VOfPCUWtK2C4_ZMpMrO3FxyS6EGlN_aCjNPBTYZyHhmMZvi7sADCFioEuDUalKlL_83AGB1fWkICmFeHudLzmUhtUq589kgKpnfQbQoT2BMznqTLJ2cIX1RRAZXYx\",\n",
    "    \"QOCKsANBYQUN4Fmrxh23mAl5Bjbi69gv3W7ChGNOmp98Q3124aytz9F2MzEPhmKOXa6EomrQAjLeGEZuvlrbsR5Q_KSnsST7Ona_K0_wafErqsrxsd68aCSe9j9IZXYx\",\n",
    "    \"NO9vZwZGnE58R8YbQDEPC90SlZ2eok4O4aYkdIxH96vUZMeSCDCvIZYY7L3VxWVYiMITiaMIkOBPRdtOgkR52BwBexnpVDDmhcjWClFRgu8uByoBopPAP8stZUBIZXYx\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + keys[kKeyIndex]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b5355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:07:17.247366Z",
     "start_time": "2023-11-11T00:07:17.240376Z"
    }
   },
   "outputs": [],
   "source": [
    "alias_to_content = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb81c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:35:24.727570Z",
     "start_time": "2023-11-11T00:34:09.577775Z"
    }
   },
   "outputs": [],
   "source": [
    "for neighborhood in neighborhoods:\n",
    "    print(\"Fetching data for \" + neighborhood)\n",
    "    \n",
    "    # Maximum results per API request.\n",
    "    limit = 50\n",
    "    location = neighborhood + \", Manhattan, NY\"\n",
    "    location = location.replace(\" \", \"+\")\n",
    "    \n",
    "    # Get up to 1000 restaurants per neighborhood.\n",
    "    for i in range(0, 1000, limit):        \n",
    "        url_params = {\n",
    "            \"location\": location,\n",
    "            \"term\": \"Restaurants\",\n",
    "            \"limit\": limit,\n",
    "            \"offset\": i,\n",
    "            \"categories\": \"(restaurants, All)\",\n",
    "            \"sort_by\": \"distance\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=url_params)\n",
    "        \n",
    "        # Max API calls gets a return status == 429!\n",
    "        if response.status_code == 429: \n",
    "            print(\"Rotating key\")\n",
    "            kKeyIndex += 1\n",
    "            headers[\"Authorization\"] = \"Bearer \" + keys[kKeyIndex]\n",
    "            response = requests.get(url, headers=headers, params=url_params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            continue\n",
    "\n",
    "        # If we already got all the businesses in a neighborhood.\n",
    "        content = json.loads(response.content)\n",
    "        if len(content[\"businesses\"]) == 0:\n",
    "            break\n",
    "\n",
    "        for business in content[\"businesses\"]:\n",
    "            alias_to_content[business[\"alias\"]] = business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427d0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:36:22.076014Z",
     "start_time": "2023-11-11T00:36:21.539270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write file.\n",
    "file_path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(file_path, \"w\") as fp:\n",
    "    json.dump(alias_to_content, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3719e9",
   "metadata": {},
   "source": [
    "## Create Reviews Files\n",
    "Make one file per letter so we can work in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df0f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T01:47:48.350977Z",
     "start_time": "2023-11-17T01:47:48.072350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read file.\n",
    "path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(path, \"r\") as json_file:\n",
    "    alias_to_content = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cdc0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T01:47:49.352258Z",
     "start_time": "2023-11-17T01:47:49.295908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make one file per letter so we can work in parallel.\n",
    "for letter in string.ascii_lowercase:\n",
    "    aliases = {a: [] for a in alias_to_content.keys() if a[0] == letter}\n",
    "    path = \"{}/reviews/{}.json\".format(os.getcwd(), letter)\n",
    "    with open(path, 'w') as fp:\n",
    "        json.dump(aliases, fp)\n",
    "        \n",
    "# And one file for all numbers and weird characters.\n",
    "aliases = {a: [] for a in alias_to_content.keys() if a[0] not in string.ascii_lowercase}\n",
    "path = \"{}/reviews/0.json\".format(os.getcwd())\n",
    "with open(path, 'w') as fp:\n",
    "    json.dump(aliases, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f5fb8",
   "metadata": {},
   "source": [
    "## Scrape Reviews Data\n",
    "No API for this. We call it with a sketchy endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c194a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T05:12:02.030885Z",
     "start_time": "2023-11-17T05:12:02.025938Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"text/html; charset=UTF-8\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f07b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T18:37:34.988580Z",
     "start_time": "2023-11-17T18:37:34.939848Z"
    }
   },
   "outputs": [],
   "source": [
    "LETTER = 'z'\n",
    "\n",
    "# Read file.\n",
    "path = \"{}/reviews/{}.json\".format(os.getcwd(), LETTER)\n",
    "with open(path, \"r\") as json_file:\n",
    "    alias_to_reviews = json.loads(json_file.read())\n",
    "\n",
    "print(\"Reviews left to fetch: {} / {}\".format(\n",
    "    sum(1 for reviews in alias_to_reviews.values() if len(reviews) == 0),\n",
    "    len(alias_to_reviews)\n",
    "))\n",
    "\n",
    "for alias, reviews in sorted(alias_to_reviews.items()):\n",
    "    # If we already scraped reviews, do not do it again.\n",
    "    if len(reviews) > 0:\n",
    "        continue\n",
    "    \n",
    "    # Gather 10 reviews per restaurant 5 times.\n",
    "    try:\n",
    "        for i in range(0, 50, 10):\n",
    "            url = \"https://www.yelp.com/biz/{}/props?start={}\".format(unidecode.unidecode(alias), i)\n",
    "            \n",
    "            request = urllib.request.Request(url, headers=headers)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            data = json.loads(response.read())\n",
    "            \n",
    "            for r in data[\"bizDetailsPageProps\"][\"reviewFeedQueryProps\"][\"reviews\"]:\n",
    "                reviews.append({\n",
    "                    \"photoCount\": r[\"user\"][\"photoCount\"],\n",
    "                    \"reviewCount\": r[\"user\"][\"reviewCount\"],\n",
    "                    \"eliteYear\": r[\"user\"][\"eliteYear\"],\n",
    "                    \"localizedDate\": r[\"localizedDate\"],\n",
    "                    \"comment\": r[\"comment\"],\n",
    "                    \"rating\": r[\"rating\"],\n",
    "                })\n",
    "                                 \n",
    "        print(\"{}: {}\".format(alias, len(reviews)))\n",
    "        if len(reviews) == 0:\n",
    "            del alias_to_reviews[alias]\n",
    "            \n",
    "    except:\n",
    "        print(\"{}: ERROR\".format(alias))\n",
    "    \n",
    "# Write file.\n",
    "path = \"{}/reviews/{}.json\".format(os.getcwd(), LETTER)\n",
    "with open(path, 'w') as fp:\n",
    "    json.dump(alias_to_reviews, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa6a6d",
   "metadata": {},
   "source": [
    "## Add Reviews to Main File\n",
    "So it is easier to use for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936cf07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T18:46:53.979311Z",
     "start_time": "2023-11-17T18:46:53.713848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read file.\n",
    "path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(path, \"r\") as json_file:\n",
    "    alias_to_content = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e079c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T18:46:58.096420Z",
     "start_time": "2023-11-17T18:46:56.781659Z"
    }
   },
   "outputs": [],
   "source": [
    "for letter in string.ascii_lowercase + '0':\n",
    "    path = \"{}/reviews/{}.json\".format(os.getcwd(), letter)\n",
    "    with open(path, \"r\") as json_file:\n",
    "        alias_to_reviews = json.loads(json_file.read())\n",
    "        for alias, reviews in alias_to_reviews.items():\n",
    "            alias_to_content[alias]['reviews'] = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c31a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
