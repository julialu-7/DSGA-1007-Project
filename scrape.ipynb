{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7d0dbe",
   "metadata": {},
   "source": [
    "Yelp API Guide: https://docs.developer.yelp.com/docs/fusion-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffff413",
   "metadata": {},
   "source": [
    "## Aggregating Yelp Restaurant Data\n",
    "Uses the v3/businesses/search endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b037cbc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T03:34:41.623893Z",
     "start_time": "2023-11-13T03:34:41.618320Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4efaae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:33:59.773074Z",
     "start_time": "2023-11-11T00:33:59.761205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate Manhattan specific restuarants by neighborhood for more granular results.\n",
    "neighborhoods = [\n",
    "    \"Alphabet City\",\n",
    "    \"Battery Park City\",\n",
    "    \"Bowery\",\n",
    "    \"Bryant Park\",\n",
    "    \"Carnegie Hill\",\n",
    "    \"Central Park\",\n",
    "    \"Chelsea\",\n",
    "    \"Chinatown\",\n",
    "    \"Civic Center\",\n",
    "    \"Clinton\",\n",
    "    \"East Harlem\",\n",
    "    \"East Village\",\n",
    "    \"Financial District\",\n",
    "    \"Flatiron\",\n",
    "    \"Fort George\",\n",
    "    \"Garment District\",\n",
    "    \"Gramercy\",\n",
    "    \"Greenwich Village\",\n",
    "    \"Hamilton Heights\",\n",
    "    \"Harlem\",\n",
    "    \"Hells Kitchen\",\n",
    "    \"Hudson Heights\",\n",
    "    \"Hudson Square\",\n",
    "    \"Hudson Yards\",\n",
    "    \"Inwood\",\n",
    "    \"Kips Bay\",\n",
    "    \"Lenox Hill\",\n",
    "    \"Lincoln Square\",\n",
    "    \"Little Italy\",\n",
    "    \"Lower East Side\",\n",
    "    \"Manhattan Valley\",\n",
    "    \"Manhattanville\",\n",
    "    \"Meatpacking\",\n",
    "    \"Midtown\",\n",
    "    \"Midtown East\",\n",
    "    \"Midtown South\",\n",
    "    \"Midtown West\",\n",
    "    \"Morningside Heights\",\n",
    "    \"Murray Hill\",\n",
    "    \"Noho\",\n",
    "    \"Nolita\",\n",
    "    \"NoMad\",\n",
    "    \"Roosevelt Island\",\n",
    "    \"Soho\",\n",
    "    \"Stuyvesant Town\",\n",
    "    \"Sutton Place\",\n",
    "    \"Times Square\",\n",
    "    \"Theater District\",\n",
    "    \"Tribeca\",\n",
    "    \"Tudor City\",\n",
    "    \"Turtle Bay\",\n",
    "    \"Two Bridges\",\n",
    "    \"Union Square\",\n",
    "    \"Upper East Side\",\n",
    "    \"Upper West Side\",\n",
    "    \"Washington Heights\",\n",
    "    \"Washington Square Park\",\n",
    "    \"West Harlem\",\n",
    "    \"West Village\",\n",
    "    \"Yorkville\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e34197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:01:04.749938Z",
     "start_time": "2023-11-11T00:01:04.744671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yelp allows inly 500 API calls per day, so we rotate btwn 3 different keys for maximum data collection.\n",
    "kKeyIndex = 0\n",
    "keys = [\n",
    "    \"ZF5VOfPCUWtK2C4_ZMpMrO3FxyS6EGlN_aCjNPBTYZyHhmMZvi7sADCFioEuDUalKlL_83AGB1fWkICmFeHudLzmUhtUq589kgKpnfQbQoT2BMznqTLJ2cIX1RRAZXYx\",\n",
    "    \"QOCKsANBYQUN4Fmrxh23mAl5Bjbi69gv3W7ChGNOmp98Q3124aytz9F2MzEPhmKOXa6EomrQAjLeGEZuvlrbsR5Q_KSnsST7Ona_K0_wafErqsrxsd68aCSe9j9IZXYx\",\n",
    "    \"NO9vZwZGnE58R8YbQDEPC90SlZ2eok4O4aYkdIxH96vUZMeSCDCvIZYY7L3VxWVYiMITiaMIkOBPRdtOgkR52BwBexnpVDDmhcjWClFRgu8uByoBopPAP8stZUBIZXYx\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + keys[kKeyIndex]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b5355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:07:17.247366Z",
     "start_time": "2023-11-11T00:07:17.240376Z"
    }
   },
   "outputs": [],
   "source": [
    "alias_to_content = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb81c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:35:24.727570Z",
     "start_time": "2023-11-11T00:34:09.577775Z"
    }
   },
   "outputs": [],
   "source": [
    "for neighborhood in neighborhoods:\n",
    "    print(\"Fetching data for \" + neighborhood)\n",
    "    \n",
    "    # Maximum results per API request.\n",
    "    limit = 50\n",
    "    location = neighborhood + \", Manhattan, NY\"\n",
    "    location = location.replace(\" \", \"+\")\n",
    "    \n",
    "    # Get up to 1000 restaurants per neighborhood.\n",
    "    for i in range(0, 1000, limit):        \n",
    "        url_params = {\n",
    "            \"location\": location,\n",
    "            \"term\": \"Restaurants\",\n",
    "            \"limit\": limit,\n",
    "            \"offset\": i,\n",
    "            \"categories\": \"(restaurants, All)\",\n",
    "            \"sort_by\": \"distance\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=url_params)\n",
    "        \n",
    "        # Max API calls gets a return status == 429!\n",
    "        if response.status_code == 429: \n",
    "            print(\"Rotating key\")\n",
    "            kKeyIndex += 1\n",
    "            headers[\"Authorization\"] = \"Bearer \" + keys[kKeyIndex]\n",
    "            response = requests.get(url, headers=headers, params=url_params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            continue\n",
    "\n",
    "        # If we already got all the businesses in a neighborhood.\n",
    "        content = json.loads(response.content)\n",
    "        if len(content[\"businesses\"]) == 0:\n",
    "            break\n",
    "\n",
    "        for business in content[\"businesses\"]:\n",
    "            alias_to_content[business[\"alias\"]] = business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427d0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T00:36:22.076014Z",
     "start_time": "2023-11-11T00:36:21.539270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write file.\n",
    "file_path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(file_path, \"w\") as fp:\n",
    "    json.dump(alias_to_content, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f5fb8",
   "metadata": {},
   "source": [
    "## Aggregating Yelp Reviews Data\n",
    "No API for this. We call it with a sketchy endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "32eef56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T03:55:15.042518Z",
     "start_time": "2023-11-13T03:55:14.703211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read file.\n",
    "file_path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    alias_to_content = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8d0c194a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T03:55:16.471657Z",
     "start_time": "2023-11-13T03:55:16.466897Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"text/html; charset=UTF-8\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a0af6ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T03:55:19.565919Z",
     "start_time": "2023-11-13T03:55:17.472185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for le-pain-quotidien-new-york-137\n",
      "Fetching for creperie-new-york-6\n",
      "Fetching for dos-toros-taqueria-new-york-5\n",
      "Fetching for umami-burger-new-york-17\n",
      "Fetching for naya-brookfield-place-new-york-3\n",
      "Fetching for sauce-pizzeria-new-york-8\n",
      "Fetching for sams-crispy-chicken-brookfield-new-york\n",
      "Fetching for hot-dog-cart-at-south-end-ave-new-york\n",
      "Fetching for skinny-pizza-new-york\n",
      "Fetching for tartinery-new-york-15\n",
      "Fetching for chopt-creative-salad-co-new-york-40\n",
      "Fetching for sams-crispy-chicken-new-york-4\n",
      "Fetching for liberty-bistro-new-york-3\n",
      "Fetching for ani-ramen-house-new-york\n",
      "Fetching for bar-a-vin-new-york-2\n",
      "Fetching for blue-ribbon-sushi-bar-hudson-eats-new-york\n",
      "Fetching for chipotle-mexican-grill-new-york-73\n",
      "Fetching for amazon-go-new-york-56\n",
      "Fetching for black-seed-bagels-at-hudson-eats-new-york\n",
      "Fetching for mighty-quinns-barbeque-new-york-4\n",
      "Fetching for springbone-kitchen-new-york-7\n",
      "Fetching for le-district-market-district-new-york\n",
      "Fetching for l-appart-new-york\n",
      "Fetching for dig-new-york-21\n",
      "Fetching for hudson-eats-new-york\n",
      "Fetching for juice-press-new-york-36\n",
      "Fetching for kimchi-taco-new-york-2\n",
      "Fetching for treadwell-park-new-york-3\n",
      "Fetching for mezze-on-the-river-new-york\n",
      "Fetching for olives-new-york-4\n",
      "Fetching for riverside-market-new-york-3\n",
      "Fetching for p-j-clarkes-new-york-8\n",
      "Fetching for sant-ambroeus-brookfield-new-york\n",
      "Fetching for joe-and-the-juice-new-york-9\n",
      "Fetching for mortons-the-steakhouse-new-york-9\n",
      "Fetching for del-friscos-grille-new-york-4\n",
      "Fetching for one-dine-new-york\n",
      "Fetching for seamores-brookfield-new-york\n",
      "Fetching for illy-caffe-new-york\n",
      "Fetching for bills-bar-and-burger-downtown-new-york\n",
      "Fetching for wasabi-sushi-and-bento-new-york-11\n",
      "Fetching for parm-new-york-4\n",
      "Fetching for metropolis-by-marcus-samuelsson-new-york\n",
      "Fetching for skinos-new-york\n",
      "Fetching for shake-shack-queens-10\n",
      "Fetching for la-pizza-and-la-pasta-at-eataly-nyc-downtown-new-york\n",
      "Fetching for blue-smoke-new-york-4\n",
      "Fetching for el-vez-burrito-bar-new-york\n",
      "Fetching for el-vez-new-york\n",
      "Fetching for jackass-burrito-new-york\n",
      "Fetching for sweetgreen-new-york-54\n",
      "Fetching for cibo-express-gourmet-market-new-york\n",
      "Fetching for two-geese-new-york\n",
      "Fetching for devon-and-blakely-new-york-10\n",
      "Fetching for schilling-restaurant-and-bar-new-york\n",
      "Fetching for mughlai-indian-cuisine-new-york-9\n",
      "Fetching for épicerie-boulud-new-york-8\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\xe9' in position 9: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Sleep or else Yelp might block your IP.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(request) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcode)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1284\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1297\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccept-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m header_names:\n\u001b[1;32m   1295\u001b[0m     skips[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip_accept_encoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mskips)\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;66;03m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;66;03m# the caller passes encode_chunked=True or the following\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# conditions hold:\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# 1. content-length has not been explicitly set\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# 2. the body is a file or iterable, but not a str or bytes-like\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# 3. Transfer-Encoding has NOT been explicitly set by the caller\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m header_names:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;66;03m# only chunk body if not explicitly set for backwards\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;66;03m# compatibility, assuming the client code is already handling the\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;66;03m# chunking\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1135\u001b[0m, in \u001b[0;36mHTTPConnection.putrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_path(url)\n\u001b[1;32m   1133\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (method, url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_vsn_str)\n\u001b[0;32m-> 1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_request(request))\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_vsn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;66;03m# Issue some standard headers for better HTTP/1.1 compliance\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_host:\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;66;03m# this header is issued *only* for HTTP/1.1\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# connections. more specifically, this means it is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[38;5;66;03m# but the host of the actual URL, not the host of the\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;66;03m# proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1215\u001b[0m, in \u001b[0;36mHTTPConnection._encode_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# ASCII also helps prevent CVE-2019-9740.\u001b[39;00m\n\u001b[0;32m-> 1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xe9' in position 9: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "for alias, content in alias_to_content.items():\n",
    "    print(\"Fetching for \" + alias)\n",
    "    \n",
    "    # If we already scraped reviews, do not do it again.\n",
    "    # Scrapes take a long time, so this allows us to scrape over multiple runs.\n",
    "    if \"reviews\" in content:\n",
    "        continue\n",
    "    \n",
    "    # Gather 10 reviews per restaurant 5 times.\n",
    "    for i in range(0, 50, 10):\n",
    "        url = \"https://www.yelp.com/biz/{}/props?start={}\".format(alias, i)\n",
    "        request = urllib.request.Request(url, headers=headers)\n",
    "        \n",
    "        # Sleep or else Yelp might block your IP.\n",
    "        time.sleep(2)\n",
    "        \n",
    "        with urllib.request.urlopen(request) as response:\n",
    "            if response.code != 200:\n",
    "                print(response.code)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                reviews = json.loads(response.read())[\"bizDetailsPageProps\"][\"reviewFeedQueryProps\"][\"reviews\"]\n",
    "                content[\"reviews\"] = content.get(\"reviews\", [])\n",
    "                \n",
    "                for r in reviews:\n",
    "                    content[\"reviews\"].append({\n",
    "                        \"photoCount\": r[\"user\"][\"photoCount\"],\n",
    "                        \"reviewCount\": r[\"user\"][\"reviewCount\"],\n",
    "                        \"eliteYear\": r[\"user\"][\"eliteYear\"],\n",
    "                        \"localizedDate\": r[\"localizedDate\"],\n",
    "                        \"comment\": r[\"comment\"],\n",
    "                        \"rating\": r[\"rating\"],\n",
    "                    })\n",
    "                    \n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9139790d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T03:52:52.348961Z",
     "start_time": "2023-11-13T03:52:51.789794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write file.\n",
    "file_path = \"{}/restaurants.json\".format(os.getcwd())\n",
    "with open(file_path, 'w') as fp:\n",
    "    json.dump(alias_to_content, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5eec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
